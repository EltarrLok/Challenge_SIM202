colsample_bytree = seq(0.5, 0.9, length.out = 5),## valeurs par défaut :
eta = 0.1,
gamma=0,min_child_weight = 1,subsample = 1)
set.seed(0)
xgb_model = train(X_train, Appliances_train, trControl = xgb_trcontrol, tuneGrid = xgbGrid,
method = "xgbTree")
X_train = xgb.DMatrix(data_prediction_train)
data_prediction_test<- as.matrix(data_prediction_test, rownames.force=NA)
data_prediction_train<- as.matrix(data_prediction_train, rownames.force=NA)
X_train = xgb.DMatrix(data_prediction_train)
data_prediction_test <- as(data_prediction_test, "sparseMatrix")
data_prediction_train <- as(data_prediction_train, "sparseMatrix")
X_train = xgb.DMatrix(data_prediction_train)
X_test =xgb.DMatrix(data_prediction_test)
xgb_trcontrol = trainControl(method = "cv", number = 5, allowParallel = TRUE,
verboseIter = FALSE, returnData = FALSE)
xgbGrid <- expand.grid(nrounds = c(100,200),  max_depth = c(3, 5, 10, 15, 20),
colsample_bytree = seq(0.5, 0.9, length.out = 5),## valeurs par défaut :
eta = 0.1,
gamma=0,min_child_weight = 1,subsample = 1)
set.seed(0)
xgb_model = train(X_train, Appliances_train, trControl = xgb_trcontrol, tuneGrid = xgbGrid,
method = "xgbTree")
data0 <- subset( data0, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors <-which(sapply(data0, is.factor))
nb_fact = length(factors) # Nombre de variables FACTOR prise dans data_train
data_num <- subset( data0, select = -factors)
data_num<-data.frame(na.approx(data_num))
data_train<-data.frame(data_num,data0[factors])
data1 <- subset( data1, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors1 <-which(sapply(data1, is.factor))
nb_fact1 = length(factors1) # Nombre de variables FACTOR prise dans data_train
data_num1 <- subset( data1, select = -factors)
data_num1<-data.frame(na.approx(data_num1))
#which(is.na(data_num1$Visibility))
data1<-data.frame(data_num1,data1[factors])
# Cette ligne sert a ne recuperer que la partie interpolation sur le test
data_local_test<- subset(data1,as.POSIXct(data1$date)<as.POSIXct(tail(data_train$date,1)))
# On recupere un echantion indexé par s sur la partie interpolation.
data_local_train <- subset(data_train,as.POSIXct(data_train$date)<as.POSIXct(tail(data_local_test$date,1)))
n <- nrow(data_local_train)
proportion <- 1-nrow(data_local_test)/nrow(data_local_train)
set.seed(2)
s <- sample(c(1:n), size=floor(n*proportion))
s<-sort(s)
n-length(s) ==nrow(data_local_test)
Appliances_test <-data_local_train$Appliances[-s]
DATEHEURE_test <- (as.numeric(as.POSIXct(data_local_train[-s,]$date))-as.numeric(as.POSIXct(data_local_train[-s,]$date[1])))/3600
# maintenant on concatene une partie a trou avec autant de trou que represente test avec une partie continue
# cette denriere correspond a la queue de train qui ne se croise pas avec test
data_local_train <- rbind(data_local_train[s,],
subset(data_train,as.POSIXct(data0$date)>as.POSIXct(tail(data_local_train$date,1))))
DATEHEURE_train<-(as.numeric(as.POSIXct(data_local_train$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
#####################################################################################################################
####### Methode Noyaux ----- ROMIN
#####################################################################################################################
plot(data0$T1,data0$Appliances)
h = 1   # h en heures
DATE_test <- (as.numeric(as.POSIXct(data1$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
noyaudata = function(i)
{
deltatemps = DATEHEURE_train-DATE_test[i]
L = dnorm(deltatemps,0,sd=sqrt(h/2))/sum(dnorm(deltatemps,0,sd=sqrt(h/2)))
L[L<1.e-5]=0
L <- as.vector(L) %*% as.vector(data_local_train$Appliances)
return(L)
}
ychap.kernel = c(1:length(DATEHEURE_test))
ychap.kernel <- pblapply(c(1:length(DATEHEURE_test)),noyaudata)
library(zoo)
source("rmse.R")
library(snpar)
library(pbapply)
library(lubridate)
library(xts)
library(npreg)
library(kernlab)
ychap.kernel = c(1:length(DATEHEURE_test))
ychap.kernel <- pblapply(c(1:length(DATEHEURE_test)),noyaudata)
xgb_model = train(X_train, Appliances_train, trControl = xgb_trcontrol, tuneGrid = xgbGrid,
method = "xgbTree")
randomForest(Appliances~., data =data_train,ntree = 271,replace=FALSE,xtest=subset(data1, select=-Appliances),
ytest=data1$Appliances,importance = TRUE,keep.forest=TRUE)
library(randomForest)
#library(ggplot2)
#library(mgcv)
#library(cowplot)
library(gam)
library(forecast)
library(corrplot)
library(car)
library(mctest)
library(ppcor)
randomForest(Appliances~., data =data_train,ntree = 271,replace=FALSE,xtest=subset(data1, select=-Appliances),
ytest=data1$Appliances,importance = TRUE,keep.forest=TRUE)
data0<-read.csv(file="train.csv", sep=",", dec='.')
data1<-read.csv(file="test.csv", sep=",", dec='.')
#str(data0)
data0 <- subset( data0, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors <-which(sapply(data0, is.factor))
nb_fact = length(factors) # Nombre de variables FACTOR prise dans data_train
data_num <- subset( data0, select = -factors)
data_num<-data.frame(na.approx(data_num))
data_train<-data.frame(data_num,data0[factors])
data1 <- subset( data1, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors1 <-which(sapply(data1, is.factor))
nb_fact1 = length(factors1) # Nombre de variables FACTOR prise dans data_train
data_num1 <- subset( data1, select = -factors)
data_num1<-data.frame(na.approx(data_num1))
#which(is.na(data_num1$Visibility))
data1<-data.frame(data_num1,data1[factors])
l<- length(subset(data1,as.POSIXct(data1$date)>as.POSIXct(tail(data_train$date,1))))
data_prediction_test<- tail(data_train,l)
data_prediction_train <- head(data_train,length(data_train$date)-l)
l<- length(subset(data1,as.POSIXct(data1$date)>as.POSIXct(tail(data_train$date,1))))
data_prediction_test<- tail(data_train,l)
randomForest(Appliances~., data =data_train,ntree = 271,replace=FALSE,xtest=subset(data_prediction_test, select=-Appliances),
ytest=data_prediction_test$Appliances,importance = TRUE,keep.forest=TRUE)
randomForest(Appliances~., data =data_train[-1,],ntree = 271,replace=FALSE,xtest=subset(data_prediction_test[-1,], select=-Appliances),
ytest=data_prediction_test[-1,]$Appliances,importance = TRUE,keep.forest=TRUE)
data_train
data0<-read.csv(file="train.csv", sep=",", dec='.')
data1<-read.csv(file="test.csv", sep=",", dec='.')
#str(data0)
data0 <- subset( data0, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors <-which(sapply(data0, is.factor))
nb_fact = length(factors) # Nombre de variables FACTOR prise dans data_train
data_num <- subset( data0, select = -factors)
data_num<-data.frame(na.approx(data_num))
data_train<-data.frame(data_num,data0[factors])
data1 <- subset( data1, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors1 <-which(sapply(data1, is.factor))
nb_fact1 = length(factors1) # Nombre de variables FACTOR prise dans data_train
data_num1 <- subset( data1, select = -factors)
data_num1<-data.frame(na.approx(data_num1))
#which(is.na(data_num1$Visibility))
data1<-data.frame(data_num1,data1[factors])
data <- rbind(data_train[-1],subset(data1,select=-Id))
### On fait le test de multi colinéarité sur le train seulement
### Ce n'est pas possible de le faire ailleurs
# names(data)
# omcdiag(data0[,c(seq(4,14,2),seq(15,19,2),26)],data0$Appliances)
# imcdiag(data0[,c(seq(4,14,2),seq(15,21,2))],data0$Appliances)
# omcdiag(data0[,c(seq(5,11,2),seq(16,20,2))],data0$Appliances)
# imcdiag(data0[,c(seq(5,11,2),seq(16,20,2))],data0$Appliances)
# round(pcor(data0[,c(seq(4,14,2),seq(15,19,2),26)],method = 'pearson')$estimate,3)
#
names(data[,c(seq(2,12,2),seq(13,19,2))])
T.pr.com <- prcomp(data[,c(seq(2,12,2),seq(13,19,2))], scale. = F)
names(T.pr.com)
head(round(T.pr.com$x,2))
biplot(T.pr.com,scale=0)
T.std_dev <- T.pr.com$sdev
T.pr_var <- T.std_dev^2
T.prop_varex <- T.pr_var/sum(T.pr_var)
plot(cumsum(T.prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
## On prend 2 PC
T_imaginaire0 <-as.matrix(data_train[,c(seq(3,13,2),seq(14,20,2))]) %*% as.matrix(T.pr.com$rotation[,1:2])
data_train <- subset(data_train,select=-c(seq(3,13,2),seq(14,20,2)))
data_train <- data.frame(data_train,T_imaginaire0)
names(data_train)
T_imaginaire1 <-as.matrix(data1[,c(seq(2,12,2),seq(13,19,2))]) %*% as.matrix(T.pr.com$rotation[,1:2])
data1 <- subset(data1,select=-c(seq(2,12,2),seq(13,19,2)))
data1 <- data.frame(data1,T_imaginaire1)
names(data1)
names(data[,c(seq(3,9,2),seq(14,19,2))])
RH.pr.com <- prcomp(data[,c(seq(3,9,2),seq(14,19,2))], scale. = F)
names(RH.pr.com)
head(round(RH.pr.com$x,2))
biplot(RH.pr.com,scale=0)
RH.std_dev <- RH.pr.com$sdev
RH.pr_var <- RH.std_dev^2
RH.prop_varex <- RH.pr_var/sum(T.pr_var)
plot(cumsum(RH.prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
## On prend 1 PC encore cette fois
RH_imaginaire <-as.matrix(data_train[,c(c(3:6),c(8:10))]) %*% as.matrix(RH.pr.com$rotation[,1])
data_train <- subset(data_train,select=-c(c(3:6),c(8:10)))
data_train <- data.frame(data_train,RH_imaginaire)
names(data_train)
RH_imaginaire <-as.matrix(data1[,c(c(2:5),c(7:9))]) %*% as.matrix(RH.pr.com$rotation[,1])
data1 <- subset(data1,select=-c(c(2:5),c(7:9)))
data1 <- data.frame(data1,RH_imaginaire)
names(data1)
randomForest(Appliances~., data =data_train[-1,],ntree = 271,replace=FALSE,xtest=subset(data_prediction_test[-1,], select=-Appliances),
ytest=data_prediction_test[-1,]$Appliances,importance = TRUE,keep.forest=TRUE)
names(data_train[-1,])
names(subset(data_prediction_test[-1,], select=-Appliances))
l<- length(subset(data1,as.POSIXct(data1$date)>as.POSIXct(tail(data_train$date,1))))
data_prediction_test<- tail(data_train,l)
data_prediction_train <- head(data_train,length(data_train$date)-l)
randomForest(Appliances~., data =data_train[-1,],ntree = 271,replace=FALSE,xtest=subset(data_prediction_test[-1,], select=-Appliances),
ytest=data_prediction_test[-1,]$Appliances,importance = TRUE,keep.forest=TRUE)
data_prediction_train <- head(data_train,length(data_train$date)-l)
names(subset(data_prediction_test[-1,], select=-Appliances))
names(data_prediction_test[-1,]$Appliances)
names(data_train[-1,])
names(subset(data_prediction_test[-1,], select=-Appliances))
randomForest(Appliances~., data =data_train[-1,],ntree = 271,replace=FALSE,xtest=subset(data_prediction_test[-1,], select=-Appliances),
ytest=data_prediction_test[-1,]$Appliances,importance = TRUE,keep.forest=TRUE)
which(sapply(data_train[-1,], is.factor))
which(sapply(data_train[-14,], is.factor))
which(sapply(data_train[,-14], is.factor))
randomForest(Appliances~., data =data_train[,-14],ntree = 271,replace=FALSE,xtest=subset(data_prediction_test[,-14], select=-Appliances),
ytest=data_prediction_test[,-14]$Appliances,importance = TRUE,keep.forest=TRUE)
RF <-randomForest(Appliances~., data =data_train[,-14],ntree = 271,replace=FALSE,xtest=subset(data_prediction_test[,-14], select=-Appliances),
ytest=data_prediction_test[,-14]$Appliances,importance = TRUE,keep.forest=TRUE)
step.model.test2 <- predict(RF,data_prediction_test)
length(ychap.kernel)
length(step.model.test2)
length(ychap.kernel)+length(step.model.test2)
length(data1)
length(nrow)
nrow(data1)
data_non_futur0 <- subset(data_train,select=-date)
data_non_futur0 <- subset(data_train,select=-date)
data_futur0 <- subset(data_train,select=-date)
data_futur0 <- subset(data_train,as.Date(data1$date)>as.Date("2016-05-10 23:50:00"))
data_non_futur0 <- subset(data_train,as.Date(data1$date)<as.Date("2016-05-11 00:00:00"))
data_futur0 <- subset(data_train,select=-date)
data_non_futur0 <- subset(data_train,select=-date)
data_futur1 <- subset(data1,as.Date(data1$date)>as.Date("2016-05-18 23:50:00"))
data_non_futur1 <- subset(data1,as.Date(data1$date)<as.Date("2016-05-19 00:00:00"))
tail(data_futur0$date)
length(data_train)
names(data_train)
data_local_test<- subset(data1,as.POSIXct(data1$date)>as.POSIXct(tail(data_train$date,1)))
nrow(data_local_test)
data_local_test<- subset(data1,as.POSIXct(data1$date)>as.POSIXct(tail(data_train$date,1)))
RF <-randomForest(Appliances~., data =data_train[,-14],ntree = 271,replace=FALSE,xtest=subset(data_local_test[,-14], select=-Appliances),
ytest=data_local_test[,-14]$Appliances,importance = TRUE,keep.forest=TRUE)
data_local_test
names(data_local_test[,-14])
names(subset(data_local_test[,-14], select=-Appliances))
names(subset(data_local_test[,-14]))
data_local_test$Appliances
data_train[,-c(1,14)]
names(data_train[,-c(1,14)])
RF <-randomForest(Appliances~., data =data_train[,-14],ntree = 271,replace=FALSE,x=data_train[,-c(1:14)],
y= data_train$Appliances,importance = TRUE,keep.forest=TRUE)
RF <-randomForest(Appliances~., data =data_train[,-14],ntree = 271,replace=FALSE,x=data_train[,-c(1:14)],
y= data_train$Appliances,xtest=subset(data_local_test[,-14], select=-Appliances),
ytest=data_train$Appliances,importance = TRUE,keep.forest=TRUE)
data_train$Appliances
RF <-randomForest(Appliances~., data =data_train[,-14],ntree = 271,replace=FALSE,x=data_train[,-c(1:14)],
y= data_train$Appliances,xtest=data_train[,-c(1:14)],
ytest=data_train$Appliances,importance = TRUE,keep.forest=TRUE)
names(train_data[,-14])
names(data_train[,-14]))
names(data_train[,-14])
RF <- randomForest(Appliances~., data =data_train[,-14],ntree = 500,replace=FALSE, importance = TRUE,
keep.forest=TRUE)
plot(RF)
source('~/Documents/ENSTA/SIM202/building-appliances/rf.R', echo=TRUE)
RF
plot(RF)
View(data_train)
RF
plot(RF)
RF <- randomForest(Appliances~., data =data_train[,-14],ntree = 270,replace=FALSE, importance = TRUE,
keep.forest=TRUE)
RF <- randomForest(Appliances~., data =data_train[,-14],ntree = 270,replace=FALSE, importance = TRUE,
keep.forest=TRUE)
data_train
rm(list = objects())
graphics.off()
setwd("/home/lokmen/Documents/ENSTA/SIM202/building-appliances/")   # set working directory
library(zoo)
source("rmse.R")
library(xgboost)
library(caret)
data0<-read.csv(file="train.csv", sep=",", dec='.')
data1<-read.csv(file="test.csv", sep=",", dec='.')
#str(data0)
data0 <- subset( data0, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors <-which(sapply(data0, is.factor))
nb_fact = length(factors) # Nombre de variables FACTOR prise dans data_train
data_num <- subset( data0, select = -factors)
data_num<-data.frame(na.approx(data_num))
data_train<-data.frame(data_num,data0[factors])
data1 <- subset( data1, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors1 <-which(sapply(data1, is.factor))
nb_fact1 = length(factors1) # Nombre de variables FACTOR prise dans data_train
data_num1 <- subset( data1, select = -factors)
data_num1<-data.frame(na.approx(data_num1))
#which(is.na(data_num1$Visibility))
data1<-data.frame(data_num1,data1[factors])
data <- rbind(data_train[-1],subset(data1,select=-Id))
### On fait le test de multi colinéarité sur le train seulement
### Ce n'est pas possible de le faire ailleurs
# names(data)
# omcdiag(data0[,c(seq(4,14,2),seq(15,19,2),26)],data0$Appliances)
# imcdiag(data0[,c(seq(4,14,2),seq(15,21,2))],data0$Appliances)
# omcdiag(data0[,c(seq(5,11,2),seq(16,20,2))],data0$Appliances)
# imcdiag(data0[,c(seq(5,11,2),seq(16,20,2))],data0$Appliances)
# round(pcor(data0[,c(seq(4,14,2),seq(15,19,2),26)],method = 'pearson')$estimate,3)
#
names(data[,c(seq(2,12,2),seq(13,19,2))])
T.pr.com <- prcomp(data[,c(seq(2,12,2),seq(13,19,2))], scale. = F)
names(T.pr.com)
head(round(T.pr.com$x,2))
biplot(T.pr.com,scale=0)
T.std_dev <- T.pr.com$sdev
T.pr_var <- T.std_dev^2
T.prop_varex <- T.pr_var/sum(T.pr_var)
plot(cumsum(T.prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
## On prend 2 PC
T_imaginaire0 <-as.matrix(data_train[,c(seq(3,13,2),seq(14,20,2))]) %*% as.matrix(T.pr.com$rotation[,1:2])
data_train <- subset(data_train,select=-c(seq(3,13,2),seq(14,20,2)))
data_train <- data.frame(data_train,T_imaginaire0)
names(data_train)
T_imaginaire1 <-as.matrix(data1[,c(seq(2,12,2),seq(13,19,2))]) %*% as.matrix(T.pr.com$rotation[,1:2])
data1 <- subset(data1,select=-c(seq(2,12,2),seq(13,19,2)))
data1 <- data.frame(data1,T_imaginaire1)
names(data1)
names(data[,c(seq(3,9,2),seq(14,19,2))])
RH.pr.com <- prcomp(data[,c(seq(3,9,2),seq(14,19,2))], scale. = F)
names(RH.pr.com)
head(round(RH.pr.com$x,2))
biplot(RH.pr.com,scale=0)
RH.std_dev <- RH.pr.com$sdev
RH.pr_var <- RH.std_dev^2
RH.prop_varex <- RH.pr_var/sum(T.pr_var)
plot(cumsum(RH.prop_varex), xlab = "Principal Component",ylab = "Cumulative Proportion of Variance Explained",type = "b")
## On prend 1 PC encore cette fois
RH_imaginaire <-as.matrix(data_train[,c(c(3:6),c(8:10))]) %*% as.matrix(RH.pr.com$rotation[,1])
data_train <- subset(data_train,select=-c(c(3:6),c(8:10)))
data_train <- data.frame(data_train,RH_imaginaire)
names(data_train)
RH_imaginaire <-as.matrix(data1[,c(c(2:5),c(7:9))]) %*% as.matrix(RH.pr.com$rotation[,1])
data1 <- subset(data1,select=-c(c(2:5),c(7:9)))
data1 <- data.frame(data1,RH_imaginaire)
names(data1)
RF <- randomForest(Appliances~., data =data_train[,-14],ntree = 270,replace=FALSE, importance = TRUE,
keep.forest=TRUE)
plot(RF)
RF
data_non_futur0 <- subset(data_train,as.Date(data1$date)<as.Date("2016-05-11 00:00:00"))
data_futur0 <- subset(data_train,select=-date)
MRF <- randomForest(Appliances~., data =data_non_futur0,ntree = 301,replace=FALSE,xtest=subset(data_futur0, select=-Appliances),
ytest=data_futur0$Appliances,importance = TRUE,keep.forest=TRUE)
length(data_non_futur0)
length(data_futur0)
names(data_non_futur0)
names(data_futur0)
MRF <- randomForest(Appliances~., data =data_non_futur0[,-14],ntree = 301,replace=FALSE,xtest=subset(data_futur0, select=-Appliances),
ytest=data_futur0$Appliances,importance = TRUE,keep.forest=TRUE)
MRF
data_futur1 <- subset(data1,as.Date(data1$date)>as.Date("2016-05-18 23:50:00"))
step.model.test2 <- predict(RF,data_futur1)
data0<-read.csv(file="train.csv", sep=",", dec='.')
data1<-read.csv(file="test.csv", sep=",", dec='.')
data0 <- subset( data0, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors <-which(sapply(data0, is.factor))
nb_fact = length(factors) # Nombre de variables FACTOR prise dans data_train
data_num <- subset( data0, select = -factors)
data_num<-data.frame(na.approx(data_num))
data_train<-data.frame(data_num,data0[factors])
data1 <- subset( data1, select = -c(Instant,InstantF,Month,DayType,WeekStatus,Heure,RH_6,
BE_wind_onshore_capacity,BE_wind_onshore_profile,rv1,rv2))
factors1 <-which(sapply(data1, is.factor))
nb_fact1 = length(factors1) # Nombre de variables FACTOR prise dans data_train
data_num1 <- subset( data1, select = -factors)
data_num1<-data.frame(na.approx(data_num1))
#which(is.na(data_num1$Visibility))
data1<-data.frame(data_num1,data1[factors])
# Cette ligne sert a ne recuperer que la partie interpolation sur le test
data_local_test<- subset(data1,as.POSIXct(data1$date)<as.POSIXct(tail(data_train$date,1)))
# On recupere un echantion indexé par s sur la partie interpolation.
data_local_train <- subset(data_train,as.POSIXct(data_train$date)<as.POSIXct(tail(data_local_test$date,1)))
n <- nrow(data_local_train)
h = 1   # h en heures
DATE_test <- (as.numeric(as.POSIXct(data1$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
noyaudata = function(i)
{
deltatemps = DATEHEURE_train-DATE_test[i]
L = dnorm(deltatemps,0,sd=sqrt(h/2))/sum(dnorm(deltatemps,0,sd=sqrt(h/2)))
L[L<1.e-5]=0
L <- as.vector(L) %*% as.vector(data_local_train$Appliances)
return(L)
}
ychap.kernel = c(1:length(DATEHEURE_test))
ychap.kernel = c(1:length(DATE_test))
ychap.kernel <- pblapply(c(1:length(DATEHEURE_test)),noyaudata)
ychap.kernel <- pblapply(c(1:length(DATE_test)),noyaudata)
ychap.kernel = c(1:length(DATE_test))
ychap.kernel <- pblapply(c(1:length(DATE_test)),noyaudata)
DATEHEURE_train<-(as.numeric(as.POSIXct(data_local_train$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
h = 1   # h en heures
noyaudata = function(i)
{
deltatemps = DATEHEURE_train-DATE_test[i]
L = dnorm(deltatemps,0,sd=sqrt(h/2))/sum(dnorm(deltatemps,0,sd=sqrt(h/2)))
L[L<1.e-5]=0
L <- as.vector(L) %*% as.vector(data_local_train$Appliances)
return(L)
}
ychap.kernel = c(1:length(DATE_test))
ychap.kernel <- pblapply(c(1:length(DATE_test)),noyaudata)
length(ychap.kernel)
length(step.model.test2)
nrow(data1)
length(ychap.kernel)+
length(step.model.test2)
length(ychap.kernel)+length(step.model.test2)
length(DATE_test)
DATE_test <- (as.numeric(as.POSIXct(data_local_test1$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
DATE_test <- (as.numeric(as.POSIXct(data_local_test$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
length(DATE_test)
h = 1   # h en heures
noyaudata = function(i)
{
deltatemps = DATEHEURE_train-DATE_test[i]
L = dnorm(deltatemps,0,sd=sqrt(h/2))/sum(dnorm(deltatemps,0,sd=sqrt(h/2)))
L[L<1.e-5]=0
L <- as.vector(L) %*% as.vector(data_local_train$Appliances)
return(L)
}
ychap.kernel = c(1:length(DATE_test))
ychap.kernel <- pblapply(c(1:length(DATE_test)),noyaudata)
length(ychap.kernel)+length(step.model.test2)
nrow(data1)
length(data_futur1)
nrow(data_futur1)
nrow(data_non_futur1)
data_non_futur1 <- subset(data1,as.Date(data1$date)<as.Date("2016-05-19 00:00:00"))
nrow(data_non_futur1
)
nrow(data_non_futur1)+1157
length(ychap.kernel)+length(step.model.test2)
length(ychap.kernel)
length(step.model.test2)
length(DATE_test)
nrow(data_local_test)
dateenheure = function(date)
{
return (time_length(interval(start = ymd_hms("2016-01-11 17:00:00"), end = ymd_hms(date)), unit = "hour"))
}
DATE = data0$date
DATE_test = pblapply(DATE, dateenheure)
length(DATE_test)
DATE = data1$date
DATE_test = pblapply(DATE, dateenheure)
DATE_test = as.numeric(DATE_test)
data_date = data.frame(DATEHEURE, data_date)
length(DATE_test)
data_futur0 <- subset(data_train,as.Date(data1$date)>as.Date("2016-05-10 23:50:00"))
data_non_futur0 <- subset(data_train,as.Date(data1$date)<as.Date("2016-05-11 00:00:00"))
data_futur0 <- subset(data_train,select=-date)
data_non_futur0 <- subset(data_train,select=-date)
nrow(data_futur1) <- subset(data1,as.Date(data1$date)>as.Date("2016-05-18 23:50:00"))
nrow(data_non_futur1) <- subset(data1,as.Date(data1$date)<as.Date("2016-05-19 00:00:00"))
data_futur1 <- subset(data1,as.Date(data1$date)>as.Date("2016-05-18 23:50:00"))
data_non_futur1 <- subset(data1,as.Date(data1$date)<as.Date("2016-05-19 00:00:00"))
nrow(data_futur1)
nrow(data_non_futur1)
DATE_test <- (as.numeric(as.POSIXct(data_futur1$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
length(DATE_test)
DATE_test <- (as.numeric(as.POSIXct(data_futur1$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
#####################################################################################################################
####### Methode Noyaux ----- ROMIN
#####################################################################################################################
h = 1   # h en heures
noyaudata = function(i)
{
deltatemps = DATEHEURE_train-DATE_test[i]
L = dnorm(deltatemps,0,sd=sqrt(h/2))/sum(dnorm(deltatemps,0,sd=sqrt(h/2)))
L[L<1.e-5]=0
L <- as.vector(L) %*% as.vector(data_local_train$Appliances)
return(L)
}
ychap.kernel = c(1:length(DATE_test))
ychap.kernel <- pblapply(c(1:length(DATE_test)),noyaudata)
length(ychap.kernel)
nrow(data_futur1)
nrow(data_non_futur0)
nrow(data_futur0)
data_futur1 <- subset(data1,as.Date(data1$date)>as.Date("2016-05-18 23:50:00"))
nrow(data_futur1)
tail(data0$date,1)
data_non_futur0 <- subset(data1,as.Date(data1$date)<as.Date("2016-05-19 00:00:00"))
length(data_non_futur0)
nrow(data_non_futur0)
DATE_test <- (as.numeric(as.POSIXct(data_non_futur0$date))-as.numeric(as.POSIXct(data_local_train$date[1])))/3600
length(ychap.kernel)+length(step.model.test2)
noyaudata = function(i)
{
deltatemps = DATEHEURE_train-DATE_test[i]
L = dnorm(deltatemps,0,sd=sqrt(h/2))/sum(dnorm(deltatemps,0,sd=sqrt(h/2)))
L[L<1.e-5]=0
L <- as.vector(L) %*% as.vector(data_local_train$Appliances)
return(L)
}
ychap.kernel = c(1:length(DATE_test))
ychap.kernel <- pblapply(c(1:length(DATE_test)),noyaudata)
length(ychap.kernel)+length(step.model.test2)
step.model.test <- c(ychap.kernel,step.model.test2)
length(step.model.test)
submit <- read.csv(file="sample_submission.csv", sep=",", dec=".")
submit$Appliances <- step.model.test
any(is.na(submit$Appliances))
which(is.na(submit$Appliances))
submit$Appliances <- na.approx(submit$Appliances)
write.table(submit, file="submission_lm.csv", quote=F, sep=",", dec='.',row.names = F)
