names(data_train)[1]<-'date'
names(data_train)[22]<-'WeekStatus'
names(data_train)[23]<-'Day_of_week'
names(data_train)[24]<-'DayType'
tail(data_train,5)
names(data_train)[length(data_train)]<-'InstantF'
names(data_train)[length(data_train)-3]<-'WeekStatus'
names(data_train)[length(data_train)-2]<-'Day_of_week'
names(data_train)[length(data_train)-1]<-'DayType'
names(data_train)[length(data_train)]<-'InstantF'
names(data_train)
which(is.na(data_train))
l <- 'Appliances ~Day_of_week'
g <- as.formula(l)
g0<-gam(g, data=data0[s,])
g0<-gam(g, data=data_train[s,])
g
l <- 'Appliances ~T1'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
summary(g0)
fitMod_gam <- function(eq, subset)
{
reg <- gam(eq, data=data0[subset,],method='REML')
return(reg)
}
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l <- 'Appliances ~T1'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
l <- 'Appliances ~Day_of_week'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
summary(g0)
cov <- head(names(data_num)[-c(1,2)], 30)
cov <- head(names(data_num)[-c(1,2)], 30)
cov
cov <- head(names(data_train)[-c(1,2)], 30)
cov
l='Appliances ~'
eq_list =list()
score = 1000
for(i in c(2:length(cov)))
{
for(k in c(1:length(cov)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
g<-lapply(eq_list, as.formula)
print(i)
reg_list <- lapply(g, fitMod_gam, subset=s)
print(i)
#print(k)
reg_list_forecast <- lapply(reg_list, predict, newdata=data0[s,])
rmse(reg_list_forecast[[1]],data0[s,]$Appliances)
rmse_list <- lapply(reg_list_forecast, rmse, data0[s,]$Appliances)
j = which.min(rmse_list) ## On repère l'indice qui minimise l'erreur
### D'abord on vérifie qu'il y a un gain à rajouter la jème variable
l
if (rmse(reg_list_forecast[[j]],data0[s,]$Appliances) <score )
{
score = rmse(reg_list_forecast[[j]],data0[s,]$Appliances)
l <- paste0(l, 's(',paste0(cov[j],')')) ## On rajoute le terme qui minimise à notre equation
l <-paste0(l, '+')
}
cov[-j]
}
reg_list <- lapply(g, fitMod_gam, subset=s)
lapply(g, fitMod_gam, subset=s)
g
names(data_train)[-c(1,2)]
reg_list <- lapply(g, fitMod_gam, subset=s)
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(i in c(2:length(cov)))
{
for(k in c(1:length(cov)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
g<-lapply(eq_list, as.formula)
print(i)
reg_list <- lapply(g, fitMod_gam, subset=s)
print(i)
#print(k)
reg_list_forecast <- lapply(reg_list, predict, newdata=data0[s,])
rmse(reg_list_forecast[[1]],data0[s,]$Appliances)
rmse_list <- lapply(reg_list_forecast, rmse, data0[s,]$Appliances)
j = which.min(rmse_list) ## On repère l'indice qui minimise l'erreur
### D'abord on vérifie qu'il y a un gain à rajouter la jème variable
l
if (rmse(reg_list_forecast[[j]],data0[s,]$Appliances) <score )
{
score = rmse(reg_list_forecast[[j]],data0[s,]$Appliances)
l <- paste0(l, 's(',paste0(cov[j],')')) ## On rajoute le terme qui minimise à notre equation
l <-paste0(l, '+')
}
cov[-j]
}
reg_list <- lapply(g, fitMod_gam, subset=s)
fitMod_gam <- function(eq, subset)
{
reg <- gam(eq, data=data0[subset,],method='REML')
print(4)
return(reg)
}
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(i in c(2:length(cov)))
{
for(k in c(1:length(cov)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
g<-lapply(eq_list, as.formula)
#print(i)
reg_list <- lapply(g, fitMod_gam, subset=s)
#print(i)
reg_list_forecast <- lapply(reg_list, predict, newdata=data0[s,])
rmse(reg_list_forecast[[1]],data0[s,]$Appliances)
rmse_list <- lapply(reg_list_forecast, rmse, data0[s,]$Appliances)
j = which.min(rmse_list) ## On repère l'indice qui minimise l'erreur
### D'abord on vérifie qu'il y a un gain à rajouter la jème variable
l
if (rmse(reg_list_forecast[[j]],data0[s,]$Appliances) <score )
{
score = rmse(reg_list_forecast[[j]],data0[s,]$Appliances)
l <- paste0(l, 's(',paste0(cov[j],')')) ## On rajoute le terme qui minimise à notre equation
l <-paste0(l, '+')
}
cov[-j]
}
cov[10] <- head(names(data_train)[-c(1,3)], 30)
cov[10]
cov <- head(names(data_train)[-c(1,3)], 30)
cov
cov[10] <- head(names(data_train)[-c(1,3)], 30)
cov[10]
cov <- head(names(data_train)[-c(1,3)], 30)
cov
eq_list[[k]]
k
eq_list[[10]]
fitMod_gam((as.formula( eq_list[[10]])))
g
#print(i)
reg_list <- lapply(g, fitMod_gam, subset=s)
fitMod_gam((as.formula( eq_list[[11]])))
#print(i)
reg_list_forecast <- lapply(reg_list, predict, newdata=data0[s,])
eq_list[[11]]
gam(Appliances~s(WeekStatus))
l <- 'Appliances ~Day_of_week'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
l <- 'Appliances ~WeekStatus'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
eq_list[[11]]
l <- 'Appliances ~s(WeekStatus)'
fitMod_gam(Appliances ~s(WeekStatus),s)
g0<-gam(g, data=data_train[s,],method='REML')
l <- 'Appliances ~s(WeekStatus)'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,],method='REML')
g0<-gam(g, data=data_train[s,])
l <- 'Appliances ~s(WeekStatus)'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
l <- 'Appliances ~WeekStatus'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
summary(g0)
which(is.na(data_train))
l <- 'Appliances ~WeekStatus'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
l <- 'Appliances ~s'WeekStatus)'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
summary(g0)
plot(g0,page=1)
par(new=TRUE)
plot(data0$T1,data0$Appliances)
######################################
######################################
###### Methode stepwise régréssion linéaire gam
#####################################""
#########################################
#data0<-data_num
fitMod_gam <- function(eq, subset)
{
reg <- gam(eq, data=data0[subset,],method='REML')
print(4)
return(reg)
}
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(i in c(2:length(cov)))
{
for(k in c(1:length(cov)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
g<-lapply(eq_list, as.formula)
#print(i)
reg_list <- lapply(g, fitMod_gam, subset=s)
#print(i)
reg_list_forecast <- lapply(reg_list, predict, newdata=data0[s,])
rmse(reg_list_forecast[[1]],data0[s,]$Appliances)
rmse_list <- lapply(reg_list_forecast, rmse, data0[s,]$Appliances)
j = which.min(rmse_list) ## On repère l'indice qui minimise l'erreur
### D'abord on vérifie qu'il y a un gain à rajouter la jème variable
l
if (rmse(reg_list_forecast[[j]],data0[s,]$Appliances) <score )
{
score = rmse(reg_list_forecast[[j]],data0[s,]$Appliances)
l <- paste0(l, 's(',paste0(cov[j],')')) ## On rajoute le terme qui minimise à notre equation
l <-paste0(l, '+')
}
cov[-j]
}
gam('data0$Appliances~data0$T1')
l<-strtrim(l,(nchar(l)-1))
l<-"Appliances ~s(NSM)+s(T3)+s(T2)+s(T_out)+s(BE_load_forecast_entsoe_transparency)+s(RH_1)+s(RH_2)+s(RH_8)+s(T1)+s(RH_9)+s(BE_load_actual_entsoe_transparency)+s(RH_7)+s(Heure)+s(Windspeed)+s(T6)+s(RH_out)+s(Instant)"
g<-"Appliances ~s(NSM)+s(T3)+s(T2)+s(T_out)+s(BE_load_forecast_entsoe_transparency)+s(RH_1)+s(RH_2)+s(RH_8)+s(T1)+s(RH_9)+s(BE_load_actual_entsoe_transparency)+s(RH_7)+s(Heure)+s(Windspeed)+s(T6)+s(RH_out)+Instant+ WeekStatus+Day_of_week+DayType+InstantF"
g<-as.formula(g)
new_reg<-fitMod_gam(g,s)
l <- 'Appliances ~s(WeekStatus)'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
l <- 'Appliances ~WeekStatus'
g <- as.formula(l)
g0<-gam(g, data=data_train[s,])
is.factor(data0$T1)
#data <- read_delim("train.csv", col_names = TRUE, delim = ",")
#data_test<- read_delim("test.csv", col_names = TRUE, delim = ",")
data0<-read.csv(file="train.csv", sep=",", dec='.')
data_test<-read.csv(file="test.csv", sep=",", dec='.')
is.factor(data0)
which(is.factor(data0))
sapply(data0,is.factor)
which(sapply(data0,is.factor))
data_num_bis<-subset( data0, select = -which(sapply(data0,is.factor)))
data_num_bis
data_num <- subset( data0, select = -c(date,WeekStatus,Day_of_week,DayType, InstantF))
data_num
rm(list = objects())
graphics.off()
setwd("/home/lokmen/Documents/ENSTA/SIM202/building-appliances/")   # set working directory
source("rmse.R")
library(readr)
library(mgcv) # modélisation non linéaire
library(tidyverse)
library(lubridate)
library(ranger)
library(zoo)
#data <- read_delim("train.csv", col_names = TRUE, delim = ",")
#data_test<- read_delim("test.csv", col_names = TRUE, delim = ",")
data0<-read.csv(file="train.csv", sep=",", dec='.')
data_test<-read.csv(file="test.csv", sep=",", dec='.')
# On se débarasse des variables qui sont des facteurs. On les voit avec la commande str()
str(data0)
#data_num <- subset( data0, select = -c(date,WeekStatus,Day_of_week,DayType, InstantF))  # méthode à la main
data_num<-subset( data0, select = -which(sapply(data0,is.factor)))   # méthode sioux
# On cherche les coeffictions fortement correlés à Appliencies
# on peut observer qu'il y a beaucoup de NA
cor(data_num)[,1]
#On utilise na.approx qui est dans me package zoo pour remplacer les NA par interpolation
data_num<-data.frame(na.approx(data_num))
# On cherche les coeffictions fortement correlés à Appliencies
# on peut observer qu'il y a beaucoup de NA
cor(data_num)[,1]
cor(data_num)[1,2:ncol(data_num)]
#il persiste une correaltion sous forme de NA. On la retire
data_num <- subset( data_num, select = -BE_wind_onshore_capacity)
cor(data_num)[1,2:ncol(data_num)]
max_corel<-max(abs(cor(data_num)[1,2:ncol(data_num)]))
liste_petit<-list()
for (i in c(ncol(data_num):2)){
if (abs(cor(data_num)[1,i])< 0.45*max_corel)
{
data_num <- subset( data_num, select =-i)
}
}
ncol(data_num)
data_train<-data.frame(data0$date,data_num,data0$WeekStatus,data0$Day_of_week,data0$DayType,data0$InstantF)
names(data_num)
names(data_train)[1]<-'date'
names(data_train)[length(data_train)-3]<-'WeekStatus'
names(data_train)[length(data_train)-2]<-'Day_of_week'
names(data_train)[length(data_train)-1]<-'DayType'
names(data_num)
names(data_train)
names(data_train)[length(data_train)]<-'InstantF'
names(data_num)
names(data_train)
which(is.na(data_train))
fitMod_gam <- function(eq, subset)
{
reg <- gam(eq, data=data0[subset,],method='REML')
print(4)
return(reg)
}
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(k in c(1:length(cov)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
eq_list
cov
is.factor((cov[[5]]))
is.factor((cov[[19]]))
is.factor((cov[[14]]))
cov[[14]]
cov[[13]]
is.factor((cov[[13]]))
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(k in c(1:length(cov)-4))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
l='Appliances ~'
eq_list =list()
score = 1000
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(k in c(1:length(cov)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
for(k in c(length(cov)-4:length(cov)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
for(k in c(1:length(cov)-4))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
length(cov)-4
c(1:length(cov)-4)
c(1:(length(cov)-4))
length(cov)
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(k in c(1:(length(cov)-4)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
for(k in c((length(cov)-3):length(cov)))
{
eq_list[[k]] <-  paste0(l,paste0(cov[[k]]))
}
eq_list
data_train
cov
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(i in c(2:length(cov)))
{
for(k in c(1:(length(cov)-4)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
for(k in c((length(cov)-3):length(cov)))
{
eq_list[[k]] <-  paste0(l,paste0(cov[[k]]))
}
g<-lapply(eq_list, as.formula)
#print(i)
reg_list <- lapply(g, fitMod_gam, subset=s)
#print(i)
reg_list_forecast <- lapply(reg_list, predict, newdata=data0[s,])
rmse(reg_list_forecast[[1]],data0[s,]$Appliances)
rmse_list <- lapply(reg_list_forecast, rmse, data0[s,]$Appliances)
j = which.min(rmse_list) ## On repère l'indice qui minimise l'erreur
### D'abord on vérifie qu'il y a un gain à rajouter la jème variable
l
if (rmse(reg_list_forecast[[j]],data0[s,]$Appliances) <score )
{
score = rmse(reg_list_forecast[[j]],data0[s,]$Appliances)
l <- paste0(l, 's(',paste0(cov[j],')')) ## On rajoute le terme qui minimise à notre equation
l <-paste0(l, '+')
}
cov[-j]
}
fitMod_gam <- function(eq, subset)
{
reg <- gam(eq, data=data0[subset,],method='REML')
return(reg)
}
cov <- head(names(data_train)[-c(1,3)], 30)
n <- nrow(data0)
set.seed(100)
s <- sample(c(1:n), size=floor(n*0.7))
length(s)
l='Appliances ~'
eq_list =list()
score = 1000
for(i in c(2:length(cov)))
{
for(k in c(1:(length(cov)-4)))
{
eq_list[[k]] <-  paste0(l, 's(',paste0(cov[[k]],')'))
}
for(k in c((length(cov)-3):length(cov)))
{
eq_list[[k]] <-  paste0(l,paste0(cov[[k]]))
}
g<-lapply(eq_list, as.formula)
print(i)
reg_list <- lapply(g, fitMod_gam, subset=s)
#print(i)
reg_list_forecast <- lapply(reg_list, predict, newdata=data0[s,])
rmse(reg_list_forecast[[1]],data0[s,]$Appliances)
rmse_list <- lapply(reg_list_forecast, rmse, data0[s,]$Appliances)
j = which.min(rmse_list) ## On repère l'indice qui minimise l'erreur
### D'abord on vérifie qu'il y a un gain à rajouter la jème variable
l
if (rmse(reg_list_forecast[[j]],data0[s,]$Appliances) <score )
{
score = rmse(reg_list_forecast[[j]],data0[s,]$Appliances)
l <- paste0(l, 's(',paste0(cov[j],')')) ## On rajoute le terme qui minimise à notre equation
l <-paste0(l, '+')
}
cov[-j]
}
score
l
l<-strtrim(l,(nchar(l)-1))
Appliance.lm = gam(l,data0)
g<-as.formula(l)
g
Appliance.gam<-fitMod_gam(g,s)
summary(Appliance.gam)
step.model.test<-predict(Appliance.gam, data_test)
summary(Appliance.gam)
step.model.test<-predict(Appliance.gam, data_test)
g
Appliance.gam
summary(Appliance.gam)
step.model.test<-predict(Appliance.gam, data_test)
predict(Appliance.gam, data_test)
data_test<-read.csv(file="test.csv", sep=",", dec='.')
#data <- read_delim("train.csv", col_names = TRUE, delim = ",")
#data_test<- read_delim("test.csv", col_names = TRUE, delim = ",")
data0<-read.csv(file="train.csv", sep=",", dec='.')
step.model.test<-predict(Appliance.gam, data_test)
step.model.test<-predict(Appliance.gam, newdata=data_test)
step.model.test<-predict(Appliance.gam, newdata=data_test)
Appliance.gam=fitMod_gam(g,s)
step.model.test<-predict(Appliance.gam, newdata=data_test)
l<-"Appliances ~s(NSM)+s(T3)+s(T2)+s(T_out)+s(BE_load_forecast_entsoe_transparency)+s(RH_1)+s(RH_2)+s(RH_8)+s(T1)+s(RH_9)+s(BE_load_actual_entsoe_transparency)+s(RH_7)+s(Heure)+s(Windspeed)+s(T6)+s(RH_out)+s(Instant)"
#g<-"Appliances ~s(NSM)+s(T3)+s(T2)+s(T_out)+s(BE_load_forecast_entsoe_transparency)+s(RH_1)+s(RH_2)+s(RH_8)+s(T1)+s(RH_9)+s(BE_load_actual_entsoe_transparency)+s(RH_7)+s(Heure)+s(Windspeed)+s(T6)+s(RH_out)+Instant+ WeekStatus+Day_of_week+DayType+InstantF"
g<-as.formula(l)
new_reg<-fitMod_gam(g,s)
